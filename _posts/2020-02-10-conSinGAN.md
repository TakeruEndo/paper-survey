sinGANの拡張モデル
---
layout: post
title: Improved Techniques for Training Single-Image GANs
summary: 階層ごとに凍結せずに学習させるsinGAN
featured-img: system
categories: CV
---


### singanとは
1. SinGANは多段階・多解像度アプローチで学習され、最初の段階では非常に低い解像度（例えば25×25ピクセル）から学習を開始
2. 学習はいくつかの「ステージ」を経て進行し、それぞれのステージでは、より多くのレイヤーがジェネレータに追加され、画像の解像度が増加
3. 各段階では、以前に学習されたすべての段階（すなわち、ジェネレーターの下位層）が凍結され、新たに追加された層のみが学習される

### 概要
- マルチステージとマルチ解像度のトレーニングをどのように扱うかが重要と考えた。
- ある時間に1つのステージのみを学習すると、異なるステージ間の相互作用が制限され、ある生成ステージから次のステージへの特徴マップの代わりに画像を伝播させることは、学習プロセスにマイナスの影響を与える。
- 逆に、すべてのステージをエンドツーエンドで学習すると、単一画像のシナリオではオーバーフィッティングが発生し、ネットワークは入力画像のみを生成するように崩壊
- 解像度の低い学習ステージが少ないと，生成された画像の品質，特に全体的な画像レイアウトの品質が急速に低下することを発見
- 解像度の低いステージでは全体的な画像レイアウトに重要であるのに対し、解像度の高いステージでは最終的な画像の質感や色に重要である
- 正しいテクスチャを持つ画像を生成するためには、高解像度の画像を用いて比較的少ない数の学習ステージで済む
- 高解像度画像の学習に使用するステージの数を減らしながら、学習中に小さな解像度の画像をより重視する方向にシフト

- これらの提案されたアーキテクチャとトレーニング方法を組み合わせることで、より少ないステージ数で現実的な画像を生成し、全体のトレーニング時間を大幅に短縮することを可能にした（オリジナルのSinGANでは120～150分だったのに対し、20～25分）

1. 異なる学習率で複数のステージを並行して学習し、生成された画像の分散と元の学習画像への適合性をトレードオフすることができる。
2. 中間段階で画像を生成するのではなく，ある段階から次の段階へ直接特徴を伝播させる．
3. 我々は、より少ない段階での訓練を可能にする多段階訓練を実現するためのスケーリングアプローチを改良した。
4. 事前に学習したモデルに対して、特定の画像やタスクに対して最適な結果を得るために使用できる微調整段階を導入する。

全ての段階を学習するのではなく、複数の段階を学習しながら、より低い段階の学習率を徐々に小さくしていくという新しいプログレッシブ成長技術を開発。1つの画像に対して複数のステージを同時に学習する。

<img width="902" alt="スクリーンショット 2021-02-11 1 01 18" src="https://user-images.githubusercontent.com/40351074/107536043-b22e9b80-6c04-11eb-881a-eff995bb6c9e.png">

上記のように、１階層の学習が終わったら、３つのConvolutional layerを挿入して学習。前の重みは固定せず、またsinGANと違って特徴量をそのまま使用している。前の段階の特徴を残差接続を行う。これを目的の解像度となるまで繰り返す。
**各ステージでノイズを加えることで、多様性を向上させている**。

### Learning rate scale
各ステージのすべての学習率の空間は大きく、最終的な画質に大きな影響を与える。任意のステージnにおいて、すべてのステージ（n, n - 1, n - 2, ...）を同じ学習率で学習するのではなく、初期のステージ（n - 1, n - 2, ...）を低い学習率で学習することで、オーバーフィッティングを減らすことができることがわかった。低い段階の学習率が大きすぎると（あるいは、同時に降ってくる段階が多すぎると）、モデル生成器はすぐに崩れてしまい、訓練画像だけが生成されてしまう。